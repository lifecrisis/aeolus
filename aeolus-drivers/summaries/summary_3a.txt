==============================================================================
Summary for Experiment #03a:

Here we run the learning tasks in the same manner as in experiment no. 2, but
we add a restriction on the output of the KDTree.query() method. Whenever
the output is returned, we filter the result list of KDNode objects
so that it includes only those nodes which have a physical distance of
less than 1.4 and a time difference of less than 7 days from that of our
query point.

The configurations for the other settings are given by the following:

    K = [10]
    N = [3, 4, 5, 6, 7, 8]
    P = [1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5]
    C = [0.001 * i for i in range(1, 25)]
    C.extend([0.025 * i for i in range(1, 81)])

The results were averaged across three random partitions under k-fold
cross validation.

Optimal MARE result:
    Folds : 10
    Neighbors : 3
    Power : 5
    Time Scale : 0.1
    MARE : 0.384419449249
    RMSPE : 185.353278024

Optimal RMSPE result:
    Folds : 10
    Neighbors : 5
    Power : 1
    Time Scale : 0.018
    MARE : 0.458033420436
    RMSPE : 123.543681264

END
==============================================================================
