==============================================================================
Summary for Experiment #03b:

Here we run the learning tasks in the same manner as in experiment no. 3A, but
we set different restrictions on the output of the KDTree.query() method.

In this experiment, we filter based on Euclidean distance, rather than on
given date and spatial distance restrictions.  The Euclidean distance
was pre-determined by building a "radius table" that mapped time-scale (c)
values to distances.  For a given time scale, the radius table mapped
that c value to a distance such that 80% of all points had AT LEAST ONE
neighbor within that distance. This distance was then used to limit what
nearest neighbors showed up in each query.  If a point had no neighbors
within that distance, we took it's single nearest neighbor as the best
guess of it's pollution value.

    K = [10]                                        # folds
    N = [3, 4, 5, 6, 7, 8]                          # neighbors
    P = [1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5]         # powers
    C = [0.001 * i for i in range(1, 25)]           # time_scales
    C.extend([0.025 * i for i in range(1, 81)])

Again, the results were averaged across three random partitions.

Optimal MARE result:
    Folds : 10
    Neighbors : 3
    Power : 5
    Time Scale : 0.1
    MARE : 0.398334782054
    RMSPE : 184.062463862

Optimal RMSPE result:
    Folds : 10
    Neighbors : 6
    Power : 1
    Time Scale : 0.024
    MARE : 0.472066424695
    RMSPE : 129.733712718

END
==============================================================================
