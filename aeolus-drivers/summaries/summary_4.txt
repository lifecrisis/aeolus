==============================================================================
Summary for Experiment #04:

For the final experiment we again average our results across three partitions.
The big difference here is that we use the bootstrap aggregation technique
from machine learning. Otherwise, the experiment is the same as in experiment
#2.  The configurations for this experiment were as follows:

    K = [10]                                        # folds
    N = [3, 4, 5, 6, 7, 8]                          # neighbors
    P = [1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5]         # powers
    C = [0.001 * i for i in range(1, 25)]           # time_scales
    C.extend([0.025 * i for i in range(1, 81)])
    A = [0.50, 0.75]                                # alphas
    M = [3]                                         # bags

Optimal MARE result:
    Folds : 10
    Neighbors : 6
    Power : 5
    Time Scale : 0.05
    Alpha : 0.75
    Bags : 3
    MARE : 0.044668315087
    RMSPE : 70.2674350158

Optimal RMSPE result:
    Folds : 10
    Neighbors : 4
    Power : 5
    Time Scale : 0.001
    Alpha : 0.5
    Bags : 3
    MARE : 0.0499884299236
    RMSPE : 9.43514322917

END
==============================================================================
